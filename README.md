# ict3104-team14-2023

This is a project built off an older genAI Model called Tune-A-Video.  This project is designed for video content creation by extracting intricate poses from videos using MMPose. This project helps bring your creative vision to life by combining the extracted poses with your choice of characters, resulting in the creation of AI-generated videos.

## Table of contents
- [Usage](#Usage)


## Usage
Follow these steps to use the project in Google Colab:
1. Open Google Colab: Go to Google Colab.

2. Open a Notebook:
Select File from the top menu.
Choose Open Notebook from the dropdown.

3. Access the Repository:
Click on the GitHub tab.
Enter the repository URL: https://github.com/YUyou0/ict3104-team14-2023.git.

4. Open the Jupyter Notebook:
Navigate to the ict3104-team14-2023 repository.
Open the Jupyter Notebook provided in the repository.

5. Execute Notebook Cells
Run the notebook cell by cell, following the steps and instructions specified within the notebook.

The notebook is seperated into 6 sections namely:Environment setup, Data exploration, Inference, Pose Extraction, Training and Testing section

Environment setup basically does as the name says, sets up the environment for the project by installing necessary packages.

Data exploration allows you to create new folders to upload input videos, and watch the playback of said videos.

Inference Section is where users will be able to generate a GIF by selecting a extracted pose and choice of character.

Pose Extraction Section allows users to select videos that they have added into the folders to extract the pose skeleton.

Training Section is where users can try to improve on the current trained model.

Testing Section allows users to test out the response time of running the inference section on different prompts and poses.

That's it! You're ready to use the project in Google Colab. Follow the notebook's guidance to make the most of its features and capabilities.







